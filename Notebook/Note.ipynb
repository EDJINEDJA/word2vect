{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutoriel pytorch \n",
    "### Torchtext overview\n",
    "\n",
    "Torchtext is a Python library that provides a suite of tools for natural language processing (NLP) tasks such as text preprocessing, tokenization, and vocabulary management. It is specifically designed for working with text data and provides several functions for cleaning and preparing text data, including removing punctuation, extra whitespaces, and other special characters, splitting text into words or tokens, and converting text to lowercase.\n",
    "\n",
    "torchtext is often used in conjunction with PyTorch, a popular deep learning framework, to build end-to-end NLP pipelines. It can be particularly useful for preparing text data for tasks such as text classification, sentiment analysis, and machine translation.\n",
    "\n",
    "The for acces to torchtext you need to dowload the library using the next command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-wf7iwzkg/pytorch_faf10091f97c497cba8e9cdbd4e51aaa/setup.py\", line 15, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "  Running setup.py install for pytorch ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for pytorch\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-wf7iwzkg/pytorch_faf10091f97c497cba8e9cdbd4e51aaa/setup.py\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m pytorch\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "Requirement already satisfied: torchtext in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: tqdm in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torchtext) (4.64.1)\n",
      "Requirement already satisfied: requests in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torchtext) (2.28.2)\n",
      "Requirement already satisfied: torch==2.0.0 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torchtext) (2.0.0)\n",
      "Requirement already satisfied: numpy in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torchtext) (1.24.2)\n",
      "Requirement already satisfied: torchdata==0.6.0 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torchtext) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (8.5.0.96)\n",
      "Requirement already satisfied: sympy in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (11.4.0.1)\n",
      "Requirement already satisfied: networkx in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (3.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (11.7.101)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (11.7.91)\n",
      "Requirement already satisfied: filelock in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torch==2.0.0->torchtext) (10.2.10.91)\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from torchdata==0.6.0->torchtext) (1.26.14)\n",
      "Requirement already satisfied: setuptools in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (67.4.0)\n",
      "Requirement already satisfied: wheel in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.26.0)\n",
      "Requirement already satisfied: lit in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from requests->torchtext) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from requests->torchtext) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n",
      "Requirement already satisfied: transformers in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (4.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: sacremoses in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: click in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from sacremoses->transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: six in /home/lnit/anaconda3/envs/lnitvenv/lib/python3.10/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Collecting SentencePiece\n",
      "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SentencePiece\n",
      "Successfully installed SentencePiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch\n",
    "! pip install torchtext\n",
    "! pip install transformers\n",
    "! pip install SentencePiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "Tokenizer is an approach used in natural language processing (nlp) to split a text in to token. \n",
    "Tokenization is the process of breaking down a text into individual words, phrases, symbols, or other meaningful elements, which are referred to as \"tokens\". These tokens can then be used for a variety of NLP tasks, such as language modeling, text classification, and sentiment analysis.\n",
    "For load it you need [torchtext.data.utils]\n",
    "\n",
    "#### get_tokenizer \n",
    "get_tokenizer from torchtext.data.utils is a method for tokenize text \n",
    "tokenizer = get_tokenizer(tokenizer method ,  language )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "def get_english_tokenizer():\n",
    "    \"\"\"\n",
    "    Documentation:\n",
    "    https://pytorch.org/text/stable/_modules/torchtext/data/utils.html#get_tokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab\n",
    "vocab is a set of word with their idx : \n",
    "words [\"je\" , \"vais\" , \"sortir\"]\n",
    "vocab(words) ----> {\"je\" : 0 ; \"vais\" :  1, \"sortir\" : 2}\n",
    "\n",
    "Then, you need to tokenize first the text befor using vocab. \n",
    "\n",
    "For use vocab in pytorch, you use the following code snippet.\n",
    "\n",
    "It take two parameters such as: data wich can be a list of words ([\"je suis parti\" , \"Il est rentré\"]) and the tokenizer function.\n",
    "add special token for the unknow word with parameter (specials = [\"<unk>\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "def build_vocab(data_iter, tokenizer):\n",
    "    \"\"\"Builds vocabulary from iterator\"\"\"\n",
    "    \n",
    "    vocab = build_vocab_from_iterator(\n",
    "        map(tokenizer, data_iter),\n",
    "        specials=[\"<unk>\"],\n",
    "        min_freq=1,\n",
    "    )\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTEXT IN NATURAL LANGUAGE PROICESSING\n",
    "Suppose you are reading a book and you come across a line of text that you don't understand. What can you do to understand it? Firstly, you should reread the entire sentence and look at the words surrounding the unfamiliar word. Once you have a clearer understanding of the context, you can then work out the meaning of the unknown word. This method of understanding an unknown word by using the context of the text is known as contextualization.\n",
    "\n",
    "Contextualization in NLP is so important for the model to understand well the whole sentence and make the relation between all words inside the sentence.\n",
    "The parameter than we use such a way to control the number of the word that we are chose before and after the unknow word (current word) is called N_CONTEXT_WORDS\n",
    "\n",
    "For by the know the entire lenght of the word tou should do this kind of operation N_CONTEXT_WORDS * 2 + 1: This max sequence length\n",
    "Batch means a bag of sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBOW_N_WORDS = 2\n",
    "MAX_SEQUENCE_LENGTH = CBOW_N_WORDS * 2 +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW (CONTEXTUAL BAG OF WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 11, 1, 8, 13]\n",
      "[4, 2, 10, 9, 12]\n",
      "[[5, 11, 8, 13], [4, 2, 9, 12]]\n",
      "[1, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5, 11,  8, 13],\n",
       "         [ 4,  2,  9, 12]]),\n",
       " tensor([ 1, 10]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def collate_cbow(batch ):\n",
    "    \"\"\"\n",
    "    Collate_fn for CBOW model to be used with Dataloader.\n",
    "    `batch` is expected to be list of text paragrahs.\n",
    "    \n",
    "    Context is represented as N=CBOW_N_WORDS past words \n",
    "    and N=CBOW_N_WORDS future words.\n",
    "    \n",
    "    Long paragraphs will be truncated to contain\n",
    "    no more that MAX_SEQUENCE_LENGTH tokens.\n",
    "    \n",
    "    Each element in `batch_input` is N=CBOW_N_WORDS*2 context words.\n",
    "    Each element in `batch_output` is a middle word.\n",
    "    \"\"\"\n",
    "    data_iter = batch\n",
    "    tokenizer = get_english_tokenizer()\n",
    "\n",
    "   \n",
    "    vocab = build_vocab(data_iter, tokenizer)\n",
    "        \n",
    "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "    batch_input, batch_output = [], []\n",
    "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "    for text in batch:\n",
    "        text_tokens_ids =text_pipeline (text)\n",
    "\n",
    "        if len(text_tokens_ids) < CBOW_N_WORDS * 2 + 1:\n",
    "            continue\n",
    "\n",
    "        if MAX_SEQUENCE_LENGTH:\n",
    "            text_tokens_ids = text_tokens_ids[:MAX_SEQUENCE_LENGTH]\n",
    "            print(text_tokens_ids)\n",
    "\n",
    "        for idx in range(len(text_tokens_ids) - CBOW_N_WORDS * 2):\n",
    "            token_id_sequence = text_tokens_ids[idx : (idx + CBOW_N_WORDS * 2 + 1)]\n",
    "            output = token_id_sequence.pop(CBOW_N_WORDS)\n",
    "            input_ = token_id_sequence\n",
    "            batch_input.append(input_)\n",
    "            batch_output.append(output)\n",
    "    print(batch_input)\n",
    "    print(batch_output)\n",
    "    batch_input = torch.tensor(batch_input, dtype=torch.long)\n",
    "    batch_output = torch.tensor(batch_output, dtype=torch.long)\n",
    "    return batch_input, batch_output\n",
    "\n",
    "collate_cbow(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('lnitvenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7da94f4bbe617fa706b25166a79bd1a71d6302505372ab0c4e237403f107a285"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
